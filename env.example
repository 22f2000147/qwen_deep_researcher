# LLM Configuration
LOCAL_LLM=qwen3:8b-q4_K_M # your model 
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434/ # default

# Research Configuration
MAX_WEB_RESEARCH_LOOPS=3

# Search Configuration
#SEARCH_API=duckduckgo
#FETCH_FULL_PAGE=true

# Output Configuration
#STRIP_THINKING_TOKENS=true
